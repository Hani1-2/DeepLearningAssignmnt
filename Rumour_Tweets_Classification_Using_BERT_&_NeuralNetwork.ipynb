{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rumour_Tweets_Classification_Using_BERT_&_NeuralNetwork.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO48420g1fBXl9XVvx7WiyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/DeepLearningAssignmnt/blob/master/Rumour_Tweets_Classification_Using_BERT_%26_NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "s61tvvN7lCFk",
        "outputId": "ae86f3be-9360-438d-b1e6-91fd277cc928"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   id                                               text  \\\n",
              "0  544297950134816768  picture gunman inside lindt cafe martin place ...   \n",
              "1  544301900682629121  police take suspect martinplace unclear whethe...   \n",
              "2  544504183341064192  escaped sydneysiege hostage elly chen top stud...   \n",
              "3  544377502563459072  ultra capitalism backflip uber rethinks fee hi...   \n",
              "4  544274934835707905  several people held hostage sydney cafe austra...   \n",
              "\n",
              "               source                      created_at   user_id  \\\n",
              "0           tweetdeck  Mon Dec 15 01:08:38 +0000 2014   9609632   \n",
              "1           tweetdeck  Mon Dec 15 01:24:20 +0000 2014  35466620   \n",
              "2  twitter web client  Mon Dec 15 14:48:08 +0000 2014  22594051   \n",
              "3           tweetdeck  Mon Dec 15 06:24:45 +0000 2014   8197942   \n",
              "4           socilflow  Sun Dec 14 23:37:11 +0000 2014    742143   \n",
              "\n",
              "           username                                   user_description  \\\n",
              "0    The Australian        news australian newspaper australian online   \n",
              "1        Herald Sun  part conversation news melbourne herald sun ne...   \n",
              "2          The Star  news updates malaysia top english language dai...   \n",
              "3          SBS News  sbs world news bringing global national news m...   \n",
              "4  BBC News (World)  world news features analysis uk news follow bb...   \n",
              "\n",
              "                     account_date          user_location  followers  \\\n",
              "0  Mon Oct 22 23:57:33 +0000 2007       sydney australia     230648   \n",
              "1  Sun Apr 26 13:44:23 +0000 2009    melbourne australia     116475   \n",
              "2  Tue Mar 03 06:19:00 +0000 2009  kuala lumpur malaysia     442770   \n",
              "3  Wed Aug 15 06:40:45 +0000 2007              australia     122339   \n",
              "4  Thu Feb 01 07:44:29 +0000 2007              london uk    8175508   \n",
              "\n",
              "   followings  retweet_count  fav_count lang                        event  \\\n",
              "0         395            226         51   en  sydneysiege-all-rnr-threads   \n",
              "1       35970            338        133   en  sydneysiege-all-rnr-threads   \n",
              "2          81            182        130   en  sydneysiege-all-rnr-threads   \n",
              "3         885            119        108   en  sydneysiege-all-rnr-threads   \n",
              "4          61            762        113   en  sydneysiege-all-rnr-threads   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32470177-4fe9-43d7-95f7-439d444a2c58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>user_description</th>\n",
              "      <th>account_date</th>\n",
              "      <th>user_location</th>\n",
              "      <th>followers</th>\n",
              "      <th>followings</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>fav_count</th>\n",
              "      <th>lang</th>\n",
              "      <th>event</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>544297950134816768</td>\n",
              "      <td>picture gunman inside lindt cafe martin place ...</td>\n",
              "      <td>tweetdeck</td>\n",
              "      <td>Mon Dec 15 01:08:38 +0000 2014</td>\n",
              "      <td>9609632</td>\n",
              "      <td>The Australian</td>\n",
              "      <td>news australian newspaper australian online</td>\n",
              "      <td>Mon Oct 22 23:57:33 +0000 2007</td>\n",
              "      <td>sydney australia</td>\n",
              "      <td>230648</td>\n",
              "      <td>395</td>\n",
              "      <td>226</td>\n",
              "      <td>51</td>\n",
              "      <td>en</td>\n",
              "      <td>sydneysiege-all-rnr-threads</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>544301900682629121</td>\n",
              "      <td>police take suspect martinplace unclear whethe...</td>\n",
              "      <td>tweetdeck</td>\n",
              "      <td>Mon Dec 15 01:24:20 +0000 2014</td>\n",
              "      <td>35466620</td>\n",
              "      <td>Herald Sun</td>\n",
              "      <td>part conversation news melbourne herald sun ne...</td>\n",
              "      <td>Sun Apr 26 13:44:23 +0000 2009</td>\n",
              "      <td>melbourne australia</td>\n",
              "      <td>116475</td>\n",
              "      <td>35970</td>\n",
              "      <td>338</td>\n",
              "      <td>133</td>\n",
              "      <td>en</td>\n",
              "      <td>sydneysiege-all-rnr-threads</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>544504183341064192</td>\n",
              "      <td>escaped sydneysiege hostage elly chen top stud...</td>\n",
              "      <td>twitter web client</td>\n",
              "      <td>Mon Dec 15 14:48:08 +0000 2014</td>\n",
              "      <td>22594051</td>\n",
              "      <td>The Star</td>\n",
              "      <td>news updates malaysia top english language dai...</td>\n",
              "      <td>Tue Mar 03 06:19:00 +0000 2009</td>\n",
              "      <td>kuala lumpur malaysia</td>\n",
              "      <td>442770</td>\n",
              "      <td>81</td>\n",
              "      <td>182</td>\n",
              "      <td>130</td>\n",
              "      <td>en</td>\n",
              "      <td>sydneysiege-all-rnr-threads</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>544377502563459072</td>\n",
              "      <td>ultra capitalism backflip uber rethinks fee hi...</td>\n",
              "      <td>tweetdeck</td>\n",
              "      <td>Mon Dec 15 06:24:45 +0000 2014</td>\n",
              "      <td>8197942</td>\n",
              "      <td>SBS News</td>\n",
              "      <td>sbs world news bringing global national news m...</td>\n",
              "      <td>Wed Aug 15 06:40:45 +0000 2007</td>\n",
              "      <td>australia</td>\n",
              "      <td>122339</td>\n",
              "      <td>885</td>\n",
              "      <td>119</td>\n",
              "      <td>108</td>\n",
              "      <td>en</td>\n",
              "      <td>sydneysiege-all-rnr-threads</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>544274934835707905</td>\n",
              "      <td>several people held hostage sydney cafe austra...</td>\n",
              "      <td>socilflow</td>\n",
              "      <td>Sun Dec 14 23:37:11 +0000 2014</td>\n",
              "      <td>742143</td>\n",
              "      <td>BBC News (World)</td>\n",
              "      <td>world news features analysis uk news follow bb...</td>\n",
              "      <td>Thu Feb 01 07:44:29 +0000 2007</td>\n",
              "      <td>london uk</td>\n",
              "      <td>8175508</td>\n",
              "      <td>61</td>\n",
              "      <td>762</td>\n",
              "      <td>113</td>\n",
              "      <td>en</td>\n",
              "      <td>sydneysiege-all-rnr-threads</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32470177-4fe9-43d7-95f7-439d444a2c58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32470177-4fe9-43d7-95f7-439d444a2c58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32470177-4fe9-43d7-95f7-439d444a2c58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/Clean_Datasetmod.csv\",encoding='ISO-8859-1')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT:\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a recent paper published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks.\n",
        "\n",
        "BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. In its vanilla form, Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task\n",
        "\n",
        "[link text](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ],
      "metadata": {
        "id": "kHlCM0mvvXTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data PreProcessing\n",
        "\n",
        "\n",
        "\n",
        "*   Frist we separate our input and target variables\n",
        "*   Then we found the values_counts which our data is highly unbiased\n",
        "\n"
      ],
      "metadata": {
        "id": "CMfDMkPWufIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_x = df[['text']]  # input features\n",
        "df_target = df[['target']] # target features"
      ],
      "metadata": {
        "id": "Le7LcQvtlvCa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " There are 4022 entries for label ‘0’ and only 1436 entries for label ‘1’. This is not a fair deal. Hence, in the next section, we will work on balancing this dataset by using the undersampling method. "
      ],
      "metadata": {
        "id": "YhA9lojIzcPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_target.value_counts() # no of tweets rumour or non-rumour"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QZIaLqul8GF",
        "outputId": "68081dbd-265d-4f7b-81b6-ca2bca8b7a5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0         4022\n",
              "1         1436\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing the Dataset\n",
        "\n",
        "There are many techniques to balance a dataset like- SMOTE, cluster abundant classes, resampling, and many others. Of these, the simplest is undersampling. In **undersampling**, the entries of the majority class are dropped till it becomes equal to the number of entries in the minority class.\n",
        "\n",
        "[techniques to handle imbalance data](https://www.youtube.com/watch?v=JnlM4yLFNuo)"
      ],
      "metadata": {
        "id": "fpWx3jsJzjfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_0_class = df_target == 0\n",
        "df_1_class = df_target == 1 \n",
        "df_0_class_undersampled = df_0_class.sample(df_1_class.shape[0])\n",
        "df = pd.concat([df_0_class_undersampled, df_1_class], axis=0)"
      ],
      "metadata": {
        "id": "dme7ken2mM3J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.value_counts() \n",
        "# since here the target is to see the power of BERT, so we are not going in balancing details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPG-OiGomjlH",
        "outputId": "f116eb81-c465-4508-e5ae-55796a5c9343"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "False     5458\n",
              "True      5458\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Dataset\n",
        "\n",
        " We are going to divide the dataset into two parts namely- the training dataset and the test dataset. There is another classification possible known as validation dataset. For the sake of simplicity, I will split the dataset in two using sklearn package."
      ],
      "metadata": {
        "id": "ACzaoN2t0K7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_x,df_target, stratify=df_target)"
      ],
      "metadata": {
        "id": "0H0rNk7vmkOe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT0MjkF1nJOb",
        "outputId": "4dc08642-3756-43f1-83da-c66fa5390554"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.9.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.26.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (14.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (1.47.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow-text) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "1_nVUBtPm2jB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Preprocessor & Encoder\n",
        "\n",
        "Here we download BERT processor and encoder via URL\n",
        "\n",
        "Recommended link: If you wanna know about more of BERT encoders. We use BERT Basic with 12 enoders \n",
        "\n",
        "[Bert processor](https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3)\n",
        "\n",
        "[Bert Encoders](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4)\n"
      ],
      "metadata": {
        "id": "33xeMO5N0Zxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "MHVHJeRtm_wJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Layers and Neural Networks\n",
        "\n",
        "we have BERT layers (the first three) followed by the neural network layer. We have included a dropout layer and eventually, the output layer will classify whether the given text is rumour or not."
      ],
      "metadata": {
        "id": "ytl6LHKF1ikW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text-layer')\n",
        "preprocessed_text = preprocess(text_input)\n",
        "outputs = encoder(preprocessed_text)\n",
        "d_layer = tf.keras.layers.Dropout(0.1, name=\"dropout-layer\")(outputs['pooled_output'])\n",
        "d_layer = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(d_layer)\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [d_layer])"
      ],
      "metadata": {
        "id": "99BE4LCEn0Lk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m= [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=m)"
      ],
      "metadata": {
        "id": "ZXDOWdEuoCBo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is tensorflow model, we have to provide here activation function which is sigmoid"
      ],
      "metadata": {
        "id": "0uZwVpYe17ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Model training will take alot of time. Since Google Colab with runtime soecified as GPU will be preferred to run the neural network.\n",
        "The model is ready to learn\n"
      ],
      "metadata": {
        "id": "eYBsrc6_2ZTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxaMdtK-pBjb",
        "outputId": "4b3a9620-b062-42e0-cbc0-1e5f395e7235"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "128/128 [==============================] - 51s 315ms/step - loss: 0.5763 - accuracy: 0.7305 - precision: 0.2174 - recall: 0.0093\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 43s 336ms/step - loss: 0.5371 - accuracy: 0.7415 - precision: 0.6267 - recall: 0.0436\n",
            "Epoch 3/10\n",
            "128/128 [==============================] - 43s 338ms/step - loss: 0.5145 - accuracy: 0.7430 - precision: 0.5984 - recall: 0.0706\n",
            "Epoch 4/10\n",
            "128/128 [==============================] - 43s 336ms/step - loss: 0.4968 - accuracy: 0.7518 - precision: 0.6266 - recall: 0.1402\n",
            "Epoch 5/10\n",
            "128/128 [==============================] - 43s 337ms/step - loss: 0.4890 - accuracy: 0.7505 - precision: 0.5875 - recall: 0.1746\n",
            "Epoch 6/10\n",
            "128/128 [==============================] - 43s 337ms/step - loss: 0.4804 - accuracy: 0.7611 - precision: 0.6364 - recall: 0.2145\n",
            "Epoch 7/10\n",
            "128/128 [==============================] - 43s 338ms/step - loss: 0.4754 - accuracy: 0.7552 - precision: 0.5904 - recall: 0.2275\n",
            "Epoch 8/10\n",
            "128/128 [==============================] - 43s 337ms/step - loss: 0.4714 - accuracy: 0.7620 - precision: 0.6152 - recall: 0.2553\n",
            "Epoch 9/10\n",
            "128/128 [==============================] - 43s 337ms/step - loss: 0.4675 - accuracy: 0.7674 - precision: 0.6200 - recall: 0.2999\n",
            "Epoch 10/10\n",
            "128/128 [==============================] - 43s 337ms/step - loss: 0.4684 - accuracy: 0.7677 - precision: 0.6296 - recall: 0.2841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f824cad20d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test) # Accuracy is about 76% on testing unseen data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3tmnxWUpEKR",
        "outputId": "aefe386e-dc82-4043-e886-108310d41f99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43/43 [==============================] - 17s 329ms/step - loss: 0.4537 - accuracy: 0.7626 - precision: 0.5907 - recall: 0.3175\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45373570919036865,\n",
              " 0.7626373767852783,\n",
              " 0.590673565864563,\n",
              " 0.3175487518310547]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Report\n",
        "\n",
        "Only better way to understand our model is confusion matrix and classification report."
      ],
      "metadata": {
        "id": "GK7r4y0e2z48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.flatten()\n",
        "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "matrix = confusion_matrix(y_test, y_predicted)\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8KE4CAtt73",
        "outputId": "3f9eaf83-3d54-4a75-c200-307e3ee1c073"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43/43 [==============================] - 16s 344ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[927,  79],\n",
              "       [245, 114]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShRk5Q-Ft9kB",
        "outputId": "758713e9-017a-43a3-9563-29e79e1eddd0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1006\n",
            "           1       0.59      0.32      0.41       359\n",
            "\n",
            "    accuracy                           0.76      1365\n",
            "   macro avg       0.69      0.62      0.63      1365\n",
            "weighted avg       0.74      0.76      0.74      1365\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k3wywoDFuGYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}