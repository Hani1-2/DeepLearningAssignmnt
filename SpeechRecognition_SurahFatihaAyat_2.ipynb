{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJbVSFeyNsjibDTezTlBRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/DeepLearningAssignmnt/blob/master/SpeechRecognition_SurahFatihaAyat_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_PATH = \"data.json\"\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "EPOCHS = 40 # iterations\n",
        "BATCH_SIZE = 32 # no of samples in one iteration\n",
        "PATIENCE = 5\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :return X (ndarray): Inputs\n",
        "    :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    print(\"Training sets loaded!\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "FM-GJmoUbN3k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(data_path, test_size=0.2, validation_size=0.2):\n",
        "    \"\"\"Creates train, validation and test sets.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :param test_size (flaot): Percentage of dataset used for testing\n",
        "    :param validation_size (float): Percentage of train set used for cross-validation\n",
        "    :return X_train (ndarray): Inputs for the train set\n",
        "    :return y_train (ndarray): Targets for the train set\n",
        "    :return X_validation (ndarray): Inputs for the validation set\n",
        "    :return y_validation (ndarray): Targets for the validation set\n",
        "    :return X_test (ndarray): Inputs for the test set\n",
        "    :return X_test (ndarray): Targets for the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load dataset\n",
        "    X, y = load_data(data_path)\n",
        "\n",
        "    # create train, validation, test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to nd array\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "\n",
        "    return X_train, y_train, X_validation, y_validation, X_test, y_test"
      ],
      "metadata": {
        "id": "HFQ_eE-obQpD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, loss=\"sparse_categorical_crossentropy\", learning_rate=0.0001):\n",
        "    \"\"\"Build neural network using keras.\n",
        "    :param input_shape (tuple): Shape of array representing a sample train. E.g.: (44, 13, 1)\n",
        "    since 44 are the segments and 13 are the co-efficient of MFCC we extracted and the depth is set as 1 (like grayscale)\n",
        "    :param loss (str): Loss function to use\n",
        "    :param learning_rate (float):\n",
        "    :return model: TensorFlow model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network architecture using convolutional layers\n",
        "    # Sequential model consist of bunch of layers one leads to another and so on\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape,\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    # down sampling the ouput layers\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # flatten output and feed into dense layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    # dropout prevent overfitting\n",
        "    tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "    # softmax output layer\n",
        "    model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "    optimiser = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss=loss,\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # print model parameters on console\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "BaBVYTLegO9o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs, batch_size, patience, X_train, y_train, X_validation, y_validation):\n",
        "    \"\"\"Trains model\n",
        "    :param epochs (int): Num training epochs\n",
        "    :param batch_size (int): Samples per batch\n",
        "    :param patience (int): Num epochs to wait before early stop, if there isn't an improvement on accuracy\n",
        "    :param X_train (ndarray): Inputs for the train set\n",
        "    :param y_train (ndarray): Targets for the train set\n",
        "    :param X_validation (ndarray): Inputs for the validation set\n",
        "    :param y_validation (ndarray): Targets for the validation set\n",
        "    :return history: Training history\n",
        "    \"\"\"\n",
        "\n",
        "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=patience)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_validation, y_validation),\n",
        "                        callbacks=[earlystop_callback])\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "Yv2gaQFOgSSk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "    :param history: Training history of model\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy subplot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    axs[0].plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy evaluation\")\n",
        "\n",
        "    # create loss subplot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"loss\")\n",
        "    axs[1].plot(history.history['val_loss'], label=\"val_loss\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Loss evaluation\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_gOBqjizgZux"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # generate train, validation and test sets\n",
        "    X_train, y_train, X_validation, y_validation, X_test, y_test = prepare_dataset(DATA_PATH)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape, learning_rate=LEARNING_RATE)\n",
        "\n",
        "    # train network\n",
        "    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)\n",
        "\n",
        "    # plot accuracy/loss for training/validation set as a function of the epochs\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate network on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))\n",
        "\n",
        "    # save model\n",
        "    m = model.save(SAVED_MODEL_PATH)\n",
        "    print(m)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HvoxKRt6gaP3",
        "outputId": "468e7a01-6556-4068-c346-3dbaa4b675e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets loaded!\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 42, 11, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 42, 11, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 21, 6, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 19, 4, 32)         18464     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 19, 4, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 10, 2, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 9, 1, 32)          4128      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 9, 1, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 1, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 160)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                10304     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,308\n",
            "Trainable params: 34,052\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8485 - accuracy: 0.7143 - val_loss: 6.4602 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/40\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7294 - accuracy: 0.8095 - val_loss: 5.7115 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/40\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6295 - accuracy: 0.8571 - val_loss: 5.1118 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/40\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5510 - accuracy: 0.9524 - val_loss: 4.6160 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/40\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4888 - accuracy: 0.9524 - val_loss: 4.2299 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/40\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4377 - accuracy: 1.0000 - val_loss: 3.9311 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/40\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3965 - accuracy: 1.0000 - val_loss: 3.6877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/40\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3612 - accuracy: 1.0000 - val_loss: 3.4909 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/40\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3306 - accuracy: 1.0000 - val_loss: 3.3400 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/40\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3044 - accuracy: 1.0000 - val_loss: 3.1927 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/40\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.2811 - accuracy: 1.0000 - val_loss: 3.0455 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6170 - accuracy: 0.1429\n",
            "\n",
            "Test loss: 2.6169700622558594, test accuracy: 14.28571492433548\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "SAMPLES_TO_CONSIDER = 22050\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "    \"\"\"Singleton class for keyword spotting inference with trained models.\n",
        "\n",
        "    :param model: Trained model\n",
        "    \"\"\"\n",
        "\n",
        "    model = None\n",
        "    _mapping = [\n",
        "        \"Alhamdu\",\n",
        "        \"lillaahi\",\n",
        "        \"Rabbil\",\n",
        "        \"aalameen\"\n",
        "    ]\n",
        "    _instance = None\n",
        "\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \"\"\"\n",
        "\n",
        "        :param file_path (str): Path to audio file to predict\n",
        "        :return predicted_keyword (str): Keyword predicted by the model\n",
        "        \"\"\"\n",
        "\n",
        "        # extract MFCC\n",
        "        MFCCs = self.preprocess(file_path)\n",
        "\n",
        "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        # get the predicted label\n",
        "        predictions = self.model.predict(MFCCs) # a 2d array [[]]\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        # index return the index which has highest score\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        print('prediction',predicted_index,predicted_keyword)\n",
        "        return predicted_keyword\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
        "        \"\"\"Extract MFCCs from audio file.\n",
        "\n",
        "        :param file_path (str): Path of audio file\n",
        "        :param num_mfcc (int): # of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply STFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for STFT. Measured in # of samples\n",
        "\n",
        "        :return MFCCs (ndarray): 2-dim array with MFCC data of shape (# time steps, # coefficients)\n",
        "        \"\"\"\n",
        "\n",
        "        # load audio file\n",
        "        signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "            # ensure consistency of the length of the signal (if the len of the array greater than trained array, we'll limit to it as per the trained array length)\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "            return MFCCs.T\n",
        "        else:\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "            return MFCCs.T\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \"\"\"Factory function for Keyword_Spotting_Service class.\n",
        "\n",
        "    :return _Keyword_Spotting_Service._instance (_Keyword_Spotting_Service):\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure an instance is created only the first time the factory function is called\n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword = kss.predict(\"012.wav\")\n",
        "    print(keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-3pn5GSi21g",
        "outputId": "c31fb9d9-b736-4daa-b844-9af735500938"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step\n",
            "prediction 0 Alhamdu\n",
            "Alhamdu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urrXDxsLjI4-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}