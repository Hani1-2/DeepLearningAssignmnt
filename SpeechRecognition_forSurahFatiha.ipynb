{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/DeepLearningAssignmnt/blob/master/SpeechRecognition_forSurahFatiha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKqYYa3QeL5s"
      },
      "source": [
        "##Pre-Processing Dataset\n",
        "Here we took 7-Ayah of surah Fatiha, consist of 8 folders, each containing 28 recordings of recitation of different recitors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRY5hEfZeSdX"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kv3YpNScaXC"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"001/002\"\n",
        "JSON_PATH = \"merged_data.json\"\n",
        "SAMPLES_TO_CONSIDER = 22050 # 1 sec. of audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tBaeykMmzUN"
      },
      "outputs": [],
      "source": [
        "# dictionary where we'll store mapping, labels, MFCCs and filenames\n",
        "data = {\n",
        "    \"mapping\": [],\n",
        "    \"labels\": [],\n",
        "    \"MFCCs\": [],\n",
        "    \"files\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMsv27Vgcf1R"
      },
      "outputs": [],
      "source": [
        "_mapping = [\n",
        "    \"Bis'mi\", #1\n",
        "    \"Al-lahi\", #2\n",
        "    \"Al-rahmaani\", #3\n",
        "    \"Al-raheemi\", #4\n",
        "    \"Alhamdu\", #5\n",
        "    \"lillaahi\", #6\n",
        "    \"Rabbil\", #7\n",
        "    \"aalameen\", #8\n",
        "    \"Ar-Rahmaan\", #9\n",
        "    \"Ar-Raheem\", #10\n",
        "    \"Maaliki\", #11\n",
        "    \"Yumid\", #12\n",
        "    \"Diin\", #13\n",
        "    \"Iyyaka\", #14\n",
        "    \"Na'abudu\", #15\n",
        "    \"Iyyaka\", #16\n",
        "    \"Nasta'een\", #17\n",
        "    \"Ihdinas\", #18\n",
        "    \"Siraatal\", #19\n",
        "    \"Mustaqeem\", #20\n",
        "    \"Siraatal\", #21\n",
        "    \"Ladheena\", #22\n",
        "    \"An'amta\", #23\n",
        "    \"Alaihim\", #24\n",
        "    \"Ghayril\", #25\n",
        "    \"Maghdubi\", #26\n",
        "    \"Alaihim\", #27\n",
        "    \"Wala al-dalina\", #28\n",
        "]\n",
        "\n",
        "def preprocess_dataset(data, dataset_path, json_path, num_mfcc=40, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file.\n",
        "    :param dataset_path (str): Path to dataset\n",
        "    :param json_path (str): Path to json file used to save MFCCs\n",
        "    :param num_mfcc (int): Number of coefficients to extract\n",
        "    :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "    :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # loop through all sub-dirs\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're at sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save label (i.e., sub-folder name) in the mapping\n",
        "            label = dirpath[-2:]\n",
        "            label = int(label)\n",
        "            print(\"label\",label)\n",
        "            data[\"mapping\"].append(_mapping[label-1])\n",
        "\n",
        "            # process all audio files in sub-dir and store MFCCs\n",
        "            for f in filenames:\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "\n",
        "                # load audio file and slice it to ensure length consistency among different files\n",
        "                signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "                # drop audio files with less than pre-decided number of samples\n",
        "                if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "\n",
        "                    # ensure consistency of the length of the signal\n",
        "                    signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "                    # extract MFCCs\n",
        "                    MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                                 hop_length=hop_length)\n",
        "\n",
        "                    # store data for analysed track\n",
        "                    data[\"MFCCs\"].append(MFCCs.T.tolist())\n",
        "                    # data[\"labels\"].append(i-1)\n",
        "                    data[\"labels\"].append(label)\n",
        "                    data[\"files\"].append(file_path)\n",
        "                    print(\"{}: {}\".format(file_path, i-1))\n",
        "\n",
        "    # save data in json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "\n",
        "# JSON_PATH = \"data7.json\"\n",
        "# if __name__ == \"__main__\":\n",
        "#     preprocess_dataset(data, DATASET_PATH, JSON_PATH)\n",
        "\n",
        "'''Combine json files'''\n",
        "merged_data = {\n",
        "    \"mapping\": [],\n",
        "    \"labels\": [],\n",
        "    \"MFCCs\": [],\n",
        "    }\n",
        "\n",
        "# Loop through each JSON file\n",
        "for filename in [\"data.json\", \"data1.json\", \"data2.json\",\"data3.json\",\"data4.json\",\"data5.json\",\"data6.json\",\"data7.json\"]:\n",
        "    with open(filename) as file:\n",
        "        data = json.load(file)\n",
        "        # Merge the data into the dictionary\n",
        "        merged_data[\"mapping\"] += data[\"mapping\"]\n",
        "        merged_data[\"labels\"]+= data[\"labels\"]\n",
        "        merged_data[\"MFCCs\"] += data[\"MFCCs\"]\n",
        "\n",
        "# Write the merged data to a new file\n",
        "with open(\"merged_data.json\", \"w\") as file:\n",
        "    json.dump(merged_data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2QHStkinGRb"
      },
      "source": [
        "##Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZcFIuDv8m3Mz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_PATH = \"merged_data.json\"\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "EPOCHS = 100 # iterations\n",
        "BATCH_SIZE = 32 # no of samples in one iteration\n",
        "PATIENCE = 5\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :return X (ndarray): Inputs\n",
        "    :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    print(\"Training sets loaded!\")\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4UE0NZaDncic"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(data_path, test_size=0.2, validation_size=0.2):\n",
        "    \"\"\"Creates train, validation and test sets.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :param test_size (flaot): Percentage of dataset used for testing\n",
        "    :param validation_size (float): Percentage of train set used for cross-validation\n",
        "    :return X_train (ndarray): Inputs for the train set\n",
        "    :return y_train (ndarray): Targets for the train set\n",
        "    :return X_validation (ndarray): Inputs for the validation set\n",
        "    :return y_validation (ndarray): Targets for the validation set\n",
        "    :return X_test (ndarray): Inputs for the test set\n",
        "    :return X_test (ndarray): Targets for the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load dataset\n",
        "    X, y = load_data(data_path)\n",
        "\n",
        "    # create train, validation, test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    print('X train dataset', X_train)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to nd array\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "\n",
        "    return X_train, y_train, X_validation, y_validation, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bZl_bMGqnjox"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape, loss=\"sparse_categorical_crossentropy\", learning_rate=0.0001):\n",
        "    \"\"\"Build neural network using keras.\n",
        "    :param input_shape (tuple): Shape of array representing a sample train. E.g.: (44, 13, 1)\n",
        "    since 44 are the segments and 13 are the co-efficient of MFCC we extracted and the depth is set as 1 (like grayscale)\n",
        "    :param loss (str): Loss function to use\n",
        "    :param learning_rate (float):\n",
        "    :return model: TensorFlow model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network architecture using convolutional layers\n",
        "    # Sequential model consist of bunch of layers one leads to another and so on\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape,\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    # down sampling the ouput layers\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # flatten output and feed into dense layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    # dropout prevent overfitting\n",
        "    tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "    # softmax output layer\n",
        "    model.add(tf.keras.layers.Dense(24, activation='softmax'))\n",
        "\n",
        "    optimiser = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss=loss,\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # print model parameters on console\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xcy1KDHbnnE7"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, batch_size, patience, X_train, y_train, X_validation, y_validation):\n",
        "    \"\"\"Trains model\n",
        "    :param epochs (int): Num training epochs\n",
        "    :param batch_size (int): Samples per batch\n",
        "    :param patience (int): Num epochs to wait before early stop, if there isn't an improvement on accuracy\n",
        "    :param X_train (ndarray): Inputs for the train set\n",
        "    :param y_train (ndarray): Targets for the train set\n",
        "    :param X_validation (ndarray): Inputs for the validation set\n",
        "    :param y_validation (ndarray): Targets for the validation set\n",
        "    :return history: Training history\n",
        "    \"\"\"\n",
        "\n",
        "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=patience)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_validation, y_validation),\n",
        "                        callbacks=[earlystop_callback])\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0FDZf5CUn0yy"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "    :param history: Training history of model\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy subplot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    axs[0].plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy evaluation\")\n",
        "\n",
        "    # create loss subplot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"loss\")\n",
        "    axs[1].plot(history.history['val_loss'], label=\"val_loss\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Loss evaluation\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "INCF5aZ3n6XG",
        "outputId": "6d93a5b6-559c-4b7b-8b7c-8ee0ff4171f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets loaded!\n",
            "X train dataset [[[-2.65659119e+02  1.40568939e+02  2.38443565e+01 ... -5.47372198e+00\n",
            "   -8.22584057e+00 -8.06210232e+00]\n",
            "  [-2.91020020e+02  1.66485901e+02  1.87493267e+01 ... -7.20124340e+00\n",
            "   -1.31074400e+01 -1.20935268e+01]\n",
            "  [-3.30785492e+02  1.79120728e+02 -1.03007441e+01 ... -9.22801685e+00\n",
            "   -2.06557941e+01 -2.22590275e+01]\n",
            "  ...\n",
            "  [-3.18247589e+02  1.80152832e+02 -1.11829739e+01 ... -5.09473419e+00\n",
            "   -1.36358023e+01 -1.08997707e+01]\n",
            "  [-3.80281799e+02  1.62989777e+02  1.07551136e+01 ... -5.50784826e+00\n",
            "   -1.49808989e+01 -3.85501242e+00]\n",
            "  [-4.84497345e+02  1.27743958e+02  4.02106171e+01 ... -2.43294239e+00\n",
            "   -1.27327785e+01 -3.20333052e+00]]\n",
            "\n",
            " [[-2.20236877e+02  1.40034637e+02  5.17758131e-01 ...  1.88024559e+01\n",
            "    9.55117416e+00  1.79312706e+01]\n",
            "  [-2.02851532e+02  1.58124756e+02 -1.54981337e+01 ...  2.63269081e+01\n",
            "    5.65015221e+00  1.40267801e+01]\n",
            "  [-2.07417145e+02  1.56857544e+02 -3.19611683e+01 ...  1.74517155e+01\n",
            "   -6.35428905e+00  3.52876520e+00]\n",
            "  ...\n",
            "  [-1.74625900e+02  1.50093933e+02 -1.41510973e+01 ...  1.66290343e+00\n",
            "   -5.33597040e+00  1.43730192e+01]\n",
            "  [-1.78568771e+02  1.40383057e+02  1.75327671e+00 ... -8.09582353e-01\n",
            "   -5.09711742e+00  8.79331970e+00]\n",
            "  [-1.72200317e+02  1.42155426e+02  1.19902096e+01 ... -2.02882290e-02\n",
            "   -5.35778189e+00  2.33198881e-01]]\n",
            "\n",
            " [[-2.09464417e+02  1.62078064e+02 -2.06304455e+01 ... -1.95062447e+00\n",
            "   -6.48961687e+00 -2.94099140e+00]\n",
            "  [-2.04863251e+02  1.39819244e+02 -2.94422131e+01 ... -4.45769215e+00\n",
            "   -8.48283005e+00 -4.97586107e+00]\n",
            "  [-2.36483704e+02  1.22189682e+02 -4.43070679e+01 ... -8.59806919e+00\n",
            "   -1.14721508e+01 -2.22599959e+00]\n",
            "  ...\n",
            "  [-2.42060242e+02  1.55651154e+02  1.32682552e+01 ...  1.89804971e+00\n",
            "   -1.73218842e+01 -3.78578663e+00]\n",
            "  [-1.63809479e+02  1.54791382e+02  1.23740540e+01 ... -9.16960239e-02\n",
            "   -1.00144310e+01 -1.91829467e+00]\n",
            "  [-1.23797104e+02  1.46395874e+02  6.90399694e+00 ... -1.56031656e+00\n",
            "   -4.48921299e+00 -8.37214708e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-3.16276703e+02  1.50650452e+02  2.35753365e+01 ...  7.76939487e+00\n",
            "    8.37969208e+00  5.15644646e+00]\n",
            "  [-2.35295319e+02  1.24904526e+02  1.48870850e+00 ...  3.86423206e+00\n",
            "    8.40776253e+00  4.13959217e+00]\n",
            "  [-2.02848022e+02  8.49490356e+01 -2.12779117e+00 ...  5.34010315e+00\n",
            "    6.36253834e+00  3.13510942e+00]\n",
            "  ...\n",
            "  [-3.15193634e+02  1.05117134e+02  1.71200180e+01 ...  5.29766655e+00\n",
            "    2.16010208e+01  2.95334473e+01]\n",
            "  [-3.05801025e+02  1.18808014e+02  2.77169075e+01 ...  2.26618147e+00\n",
            "    1.38222847e+01  2.16544838e+01]\n",
            "  [-3.16210602e+02  1.30377350e+02  3.70143738e+01 ... -4.52635002e+00\n",
            "    6.09209824e+00  1.72119293e+01]]\n",
            "\n",
            " [[ 2.79654598e+01  1.37490143e+02 -2.18854332e+01 ... -4.18167639e+00\n",
            "   -9.61881828e+00 -3.86868143e+00]\n",
            "  [ 2.45495853e+01  1.43282608e+02 -2.76192245e+01 ... -6.03713322e+00\n",
            "   -1.17628841e+01 -4.78587866e+00]\n",
            "  [-4.34358330e+01  1.62111725e+02 -1.91446819e+01 ... -8.95537949e+00\n",
            "   -9.80460644e+00 -3.07975817e+00]\n",
            "  ...\n",
            "  [-6.04006920e+01  1.04073517e+02 -2.67083435e+01 ... -1.67100680e+00\n",
            "   -8.04811478e+00 -1.04903364e+00]\n",
            "  [-4.05396690e+01  1.22626862e+02 -3.76807499e+00 ... -2.63235092e-01\n",
            "   -8.65594864e+00 -2.59696341e+00]\n",
            "  [-3.49865837e+01  1.43330276e+02  4.81909561e+00 ...  7.98008919e-01\n",
            "   -5.34347820e+00 -3.89487934e+00]]\n",
            "\n",
            " [[-1.09877182e+02  1.70674835e+02 -1.51035862e+01 ... -4.94685602e+00\n",
            "   -1.97740674e+00 -3.56597376e+00]\n",
            "  [-1.31794281e+02  1.66876770e+02 -2.99387856e+01 ... -5.32744884e+00\n",
            "   -7.75716543e+00 -7.69467926e+00]\n",
            "  [-1.68423355e+02  1.64192871e+02 -5.95595398e+01 ... -5.04811287e+00\n",
            "   -1.75284653e+01 -1.04054337e+01]\n",
            "  ...\n",
            "  [-2.56913422e+02  8.28218613e+01  9.74796104e+00 ... -1.31417589e+01\n",
            "   -6.43697262e+00 -1.96058369e+00]\n",
            "  [-2.34658936e+02  1.00122772e+02  2.75512962e+01 ... -7.81530428e+00\n",
            "   -1.26536298e+00  8.18439960e-01]\n",
            "  [-2.28781631e+02  1.10485413e+02  3.07201309e+01 ... -6.51673365e+00\n",
            "   -1.56213927e+00  1.80657983e-01]]]\n",
            "X_train [[[-146.68504333]\n",
            "  [ 147.46871948]\n",
            "  [  10.8592205 ]\n",
            "  ...\n",
            "  [  -4.13809919]\n",
            "  [   0.36739346]\n",
            "  [   2.92774868]]\n",
            "\n",
            " [[-132.16673279]\n",
            "  [ 164.08062744]\n",
            "  [ -17.62541962]\n",
            "  ...\n",
            "  [  -4.78588915]\n",
            "  [  -3.10376024]\n",
            "  [  -4.8936739 ]]\n",
            "\n",
            " [[-144.90739441]\n",
            "  [ 155.17532349]\n",
            "  [ -34.95709229]\n",
            "  ...\n",
            "  [  -1.41101861]\n",
            "  [  -4.95940733]\n",
            "  [  -8.47308445]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-237.36167908]\n",
            "  [ 103.46583557]\n",
            "  [   6.7900424 ]\n",
            "  ...\n",
            "  [  -9.24727345]\n",
            "  [  -0.77376133]\n",
            "  [  -4.41930437]]\n",
            "\n",
            " [[-228.05735779]\n",
            "  [ 114.92475891]\n",
            "  [  16.48383331]\n",
            "  ...\n",
            "  [ -13.55937576]\n",
            "  [  -2.28093982]\n",
            "  [  -4.07252312]]\n",
            "\n",
            " [[-226.9276886 ]\n",
            "  [ 132.97320557]\n",
            "  [  20.91211128]\n",
            "  ...\n",
            "  [ -14.23716545]\n",
            "  [  -2.28312206]\n",
            "  [  -2.70716   ]]]\n",
            "y_train [17 26 17 27 10  6 27 10 10  4 19  8 10 10 20 10 10 28 18 14 22 10 28  9\n",
            "  8 28 22 20 13  3  8  9  9  8 16 24 13 23  9 23 22  3  4 16 24 20 24 24\n",
            " 28  3 27 20 10 16  3 26  8 17  8 26  8  8 28 27 24  3 22 13 20 28 17 10\n",
            "  3 17 16 26 26 20  8 23  4 20 16 13  3  3 16  3 24 26 17  8 26 28  6 10\n",
            " 26 17 28 13 26 26 22 28 17  4 16 14 10 13 23  4 26 16 24 16 23 19 20 16\n",
            " 17  9 14 27  9 17 16  9 13 19  8 16  5  9 23 28 27 17  6 10 27 28 13  4\n",
            " 17 15 13  3 28 23 10 28 14  8 13  4 27 20  4 13  5 22 28 13 16 28 20 22\n",
            " 22 20 19  4  8 26 20 27 17 20 25  9 20 19 19  4  8 23 26 13 23 16  4 24\n",
            " 27 17 17 16 22  3 23 24 17 26 26 10 28 24 23 27 13 23  4 17 20 17  3 27\n",
            "  4  9 16  8 16  4 28 22 16 28 13 24  9  9  4 22 20  9  8 10  8 13 20  4\n",
            " 13 13 27  4]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 42, 38, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 42, 38, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 21, 19, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 19, 17, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 19, 17, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 10, 9, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 9, 8, 32)          4128      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 9, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                41024     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 24)                1560      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,328\n",
            "Trainable params: 66,072\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 49ms/step - loss: nan - accuracy: 0.0123 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # generate train, validation and test sets\n",
        "    X_train, y_train, X_validation, y_validation, X_test, y_test = prepare_dataset(DATA_PATH)\n",
        "    print('X_train',X_train[0])\n",
        "    print('y_train',y_train)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape=input_shape, learning_rate=LEARNING_RATE)\n",
        "\n",
        "    # train network\n",
        "    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)\n",
        "\n",
        "    # plot accuracy/loss for training/validation set as a function of the epochs\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate network on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    # print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))\n",
        "\n",
        "    # save model\n",
        "    m = model.save(SAVED_MODEL_PATH)\n",
        "    print(m)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "SAMPLES_TO_CONSIDER = 22050\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "    \"\"\"Singleton class for keyword spotting inference with trained models.\n",
        "\n",
        "    :param model: Trained model\n",
        "    \"\"\"\n",
        "\n",
        "    model = None\n",
        "    _mapping = {\n",
        "    1:\"Bis'mi\",\n",
        "    2:\"Al-lahi\",\n",
        "    3:\"Al-rahmaani\",\n",
        "    4:\"Al-raheemi\",\n",
        "    5:\"Alhamdu\",\n",
        "    6:\"lillaahi\",\n",
        "    7:\"Rabbil\",\n",
        "    8:\"aalameen\",\n",
        "    9:\"Ar-Rahmaan\",\n",
        "    10:\"Ar-Raheem\",\n",
        "    11:\"Maaliki\",\n",
        "    12:\"Yumid\",\n",
        "    13:\"Diin\",\n",
        "    14:\"Iyyaka\",\n",
        "    15:\"Na'abudu\",\n",
        "    16:\"Iyyaka\",\n",
        "    17:\"Nasta'een\",\n",
        "    18:\"Ihdinas\",\n",
        "    19:\"Siraatal\",\n",
        "    20:\"Mustaqeem\",\n",
        "    21:\"Siraatal\",\n",
        "    22:\"Ladheena\",\n",
        "    23:\"An'amta\",\n",
        "    24:\"Alaihim\",\n",
        "    25:\"Ghayril\",\n",
        "    26:\"Maghdubi\",\n",
        "    27:\"Alaihim\",\n",
        "    28:\"Wala al-dalina\"\n",
        "}\n",
        "\n",
        "    _instance = None\n",
        "\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \"\"\"\n",
        "\n",
        "        :param file_path (str): Path to audio file to predict\n",
        "        :return predicted_keyword (str): Keyword predicted by the model\n",
        "        \"\"\"\n",
        "\n",
        "        # extract MFCC\n",
        "        MFCCs = self.preprocess(file_path)\n",
        "\n",
        "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        # get the predicted label\n",
        "        predictions = self.model.predict(MFCCs) # a 2d array [[]]\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        print('predicted index',predicted_index)\n",
        "        # index return the index which has highest score\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        # print('prediction',predicted_index,predicted_keyword)\n",
        "        return predicted_keyword\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=40, n_fft=2048, hop_length=512):\n",
        "        \"\"\"Extract MFCCs from audio file.\n",
        "\n",
        "        :param file_path (str): Path of audio file\n",
        "        :param num_mfcc (int): # of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply STFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for STFT. Measured in # of samples\n",
        "\n",
        "        :return MFCCs (ndarray): 2-dim array with MFCC data of shape (# time steps, # coefficients)\n",
        "        \"\"\"\n",
        "\n",
        "        # load audio file\n",
        "        signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "            # ensure consistency of the length of the signal (if the len of the array greater than trained array, we'll limit to it as per the trained array length)\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "            return MFCCs.T\n",
        "        else:\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "            return MFCCs.T\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \"\"\"Factory function for Keyword_Spotting_Service class.\n",
        "\n",
        "    :return _Keyword_Spotting_Service._instance (_Keyword_Spotting_Service):\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure an instance is created only the first time the factory function is called\n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n"
      ],
      "metadata": {
        "id": "jumpKqOwTvg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword = kss.predict(\"012.wav\")\n",
        "    print(keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPTnzIvCWkOW",
        "outputId": "f3983928-781c-4ef5-b1b2-3dd6fabc3320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step\n",
            "predicted index 8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UimezjXdWn0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1yugasZphHK9upW8HKd7QUf5nrK9JOqKe",
      "authorship_tag": "ABX9TyPaAp6q+DV6YO7+hVotNdkN",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}