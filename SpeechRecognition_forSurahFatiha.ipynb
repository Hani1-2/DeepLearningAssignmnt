{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hani1-2/DeepLearningAssignmnt/blob/master/SpeechRecognition_forSurahFatiha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKqYYa3QeL5s"
      },
      "source": [
        "##Pre-Processing Dataset\n",
        "Here we took 7-Ayah of surah Fatiha, consist of 8 folders, each containing 28 recordings of recitation of different recitors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YRY5hEfZeSdX"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Kv3YpNScaXC"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"001/002\"\n",
        "JSON_PATH = \"merged_data.json\"\n",
        "SAMPLES_TO_CONSIDER = 22050 # 1 sec. of audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6tBaeykMmzUN"
      },
      "outputs": [],
      "source": [
        "# dictionary where we'll store mapping, labels, MFCCs and filenames\n",
        "data = {\n",
        "    \"mapping\": [],\n",
        "    \"labels\": [],\n",
        "    \"MFCCs\": [],\n",
        "    \"files\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMsv27Vgcf1R"
      },
      "outputs": [],
      "source": [
        "_mapping = [\n",
        "    \"Bis'mi\", #1\n",
        "    \"Al-lahi\", #2\n",
        "    \"Al-rahmaani\", #3\n",
        "    \"Al-raheemi\", #4\n",
        "    \"Alhamdu\", #5\n",
        "    \"lillaahi\", #6\n",
        "    \"Rabbil\", #7\n",
        "    \"aalameen\", #8\n",
        "    \"Ar-Rahmaan\", #9\n",
        "    \"Ar-Raheem\", #10\n",
        "    \"Maaliki\", #11\n",
        "    \"Yumid\", #12\n",
        "    \"Diin\", #13\n",
        "    \"Iyyaka\", #14\n",
        "    \"Na'abudu\", #15\n",
        "    \"Iyyaka\", #16\n",
        "    \"Nasta'een\", #17\n",
        "    \"Ihdinas\", #18\n",
        "    \"Siraatal\", #19\n",
        "    \"Mustaqeem\", #20\n",
        "    \"Siraatal\", #21\n",
        "    \"Ladheena\", #22\n",
        "    \"An'amta\", #23\n",
        "    \"Alaihim\", #24\n",
        "    \"Ghayril\", #25\n",
        "    \"Maghdubi\", #26\n",
        "    \"Alaihim\", #27\n",
        "    \"Wala al-dalina\", #28\n",
        "]\n",
        "\n",
        "def preprocess_dataset(data, dataset_path, json_path, num_mfcc=40, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file.\n",
        "    :param dataset_path (str): Path to dataset\n",
        "    :param json_path (str): Path to json file used to save MFCCs\n",
        "    :param num_mfcc (int): Number of coefficients to extract\n",
        "    :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "    :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    # loop through all sub-dirs\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're at sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save label (i.e., sub-folder name) in the mapping\n",
        "            label = dirpath[-2:]\n",
        "            label = int(label)\n",
        "            print(\"label\",label)\n",
        "            data[\"mapping\"].append(_mapping[label-1])\n",
        "\n",
        "            # process all audio files in sub-dir and store MFCCs\n",
        "            for f in filenames:\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "\n",
        "                # load audio file and slice it to ensure length consistency among different files\n",
        "                signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "                # drop audio files with less than pre-decided number of samples\n",
        "                if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "\n",
        "                    # ensure consistency of the length of the signal\n",
        "                    signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "                    # extract MFCCs\n",
        "                    MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                                 hop_length=hop_length)\n",
        "\n",
        "                    # store data for analysed track\n",
        "                    data[\"MFCCs\"].append(MFCCs.T.tolist())\n",
        "                    # data[\"labels\"].append(i-1)\n",
        "                    data[\"labels\"].append(label)\n",
        "                    data[\"files\"].append(file_path)\n",
        "                    print(\"{}: {}\".format(file_path, i-1))\n",
        "\n",
        "    # save data in json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "\n",
        "# JSON_PATH = \"data7.json\"\n",
        "# if __name__ == \"__main__\":\n",
        "#     preprocess_dataset(data, DATASET_PATH, JSON_PATH)\n",
        "\n",
        "'''Combine json files'''\n",
        "merged_data = {\n",
        "    \"mapping\": [],\n",
        "    \"labels\": [],\n",
        "    \"MFCCs\": [],\n",
        "    }\n",
        "\n",
        "# Loop through each JSON file\n",
        "for filename in [\"data.json\", \"data1.json\", \"data2.json\",\"data3.json\",\"data4.json\",\"data5.json\",\"data6.json\",\"data7.json\"]:\n",
        "    with open(filename) as file:\n",
        "        data = json.load(file)\n",
        "        # Merge the data into the dictionary\n",
        "        merged_data[\"mapping\"] += data[\"mapping\"]\n",
        "        merged_data[\"labels\"]+= data[\"labels\"]\n",
        "        merged_data[\"MFCCs\"] += data[\"MFCCs\"]\n",
        "\n",
        "# Write the merged data to a new file\n",
        "with open(\"merged_data.json\", \"w\") as file:\n",
        "    json.dump(merged_data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2QHStkinGRb"
      },
      "source": [
        "##Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZcFIuDv8m3Mz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_PATH = \"data_a12.json\"\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "EPOCHS = 100 # iterations\n",
        "BATCH_SIZE = 32 # no of samples in one iteration\n",
        "PATIENCE = 5\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :return X (ndarray): Inputs\n",
        "    :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"MFCCs\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    print(\"Training sets loaded!\")\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4UE0NZaDncic"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(data_path, test_size=0.2, validation_size=0.2):\n",
        "    \"\"\"Creates train, validation and test sets.\n",
        "    :param data_path (str): Path to json file containing data\n",
        "    :param test_size (flaot): Percentage of dataset used for testing\n",
        "    :param validation_size (float): Percentage of train set used for cross-validation\n",
        "    :return X_train (ndarray): Inputs for the train set\n",
        "    :return y_train (ndarray): Targets for the train set\n",
        "    :return X_validation (ndarray): Inputs for the validation set\n",
        "    :return y_validation (ndarray): Targets for the validation set\n",
        "    :return X_test (ndarray): Inputs for the test set\n",
        "    :return X_test (ndarray): Targets for the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load dataset\n",
        "    X, y = load_data(data_path)\n",
        "\n",
        "    # create train, validation, test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    print('X train dataset', X_train)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to nd array\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "\n",
        "    return X_train, y_train, X_validation, y_validation, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bZl_bMGqnjox"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape, loss=\"sparse_categorical_crossentropy\", learning_rate=0.0001):\n",
        "    \"\"\"Build neural network using keras.\n",
        "    :param input_shape (tuple): Shape of array representing a sample train. E.g.: (44, 13, 1)\n",
        "    since 44 are the segments and 13 are the co-efficient of MFCC we extracted and the depth is set as 1 (like grayscale)\n",
        "    :param loss (str): Loss function to use\n",
        "    :param learning_rate (float):\n",
        "    :return model: TensorFlow model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network architecture using convolutional layers\n",
        "    # Sequential model consist of bunch of layers one leads to another and so on\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape,\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    # down sampling the ouput layers\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # flatten output and feed into dense layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    # dropout prevent overfitting\n",
        "    tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "    # softmax output layer\n",
        "    model.add(tf.keras.layers.Dense(27, activation='softmax'))\n",
        "\n",
        "    optimiser = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss=loss,\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # print model parameters on console\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xcy1KDHbnnE7"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, batch_size, patience, X_train, y_train, X_validation, y_validation):\n",
        "    \"\"\"Trains model\n",
        "    :param epochs (int): Num training epochs\n",
        "    :param batch_size (int): Samples per batch\n",
        "    :param patience (int): Num epochs to wait before early stop, if there isn't an improvement on accuracy\n",
        "    :param X_train (ndarray): Inputs for the train set\n",
        "    :param y_train (ndarray): Targets for the train set\n",
        "    :param X_validation (ndarray): Inputs for the validation set\n",
        "    :param y_validation (ndarray): Targets for the validation set\n",
        "    :return history: Training history\n",
        "    \"\"\"\n",
        "\n",
        "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=patience)\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_data=(X_validation, y_validation),\n",
        "                        callbacks=[earlystop_callback])\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0FDZf5CUn0yy"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "    :param history: Training history of model\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy subplot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    axs[0].plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy evaluation\")\n",
        "\n",
        "    # create loss subplot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"loss\")\n",
        "    axs[1].plot(history.history['val_loss'], label=\"val_loss\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Loss evaluation\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "INCF5aZ3n6XG",
        "outputId": "57426496-1fed-477e-d135-be1d37c74e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets loaded!\n",
            "X train dataset [[[-1.81904343e+02  1.63071808e+02  1.53573122e+01 ...  2.37216353e-01\n",
            "    1.05100689e+01  1.78078499e+01]\n",
            "  [-2.02787308e+02  1.96381241e+02  1.28288326e+01 ...  3.05340481e+00\n",
            "    1.41372414e+01  2.19204063e+01]\n",
            "  [-2.35148392e+02  2.18943726e+02  9.48603439e+00 ...  6.83639526e+00\n",
            "    1.71930904e+01  2.37729950e+01]\n",
            "  ...\n",
            "  [-2.27421829e+02  1.60124664e+02 -2.19633865e+01 ...  2.25339050e+01\n",
            "    1.69014530e+01  2.03290901e+01]\n",
            "  [-1.45937622e+02  1.25190384e+02 -1.81396961e+00 ...  1.79532490e+01\n",
            "    1.41880264e+01  1.41362276e+01]\n",
            "  [-1.10720261e+02  1.15470177e+02  9.40768814e+00 ...  1.24782677e+01\n",
            "    6.82256079e+00  8.74225903e+00]]\n",
            "\n",
            " [[-1.74260941e+02  1.45080292e+02  4.83571172e-01 ... -1.12236404e+01\n",
            "   -1.06122217e+01 -3.95807576e+00]\n",
            "  [-1.19956116e+02  1.46377655e+02 -2.13994102e+01 ... -3.80618000e+00\n",
            "   -1.02587051e+01 -3.59400034e+00]\n",
            "  [-9.00876389e+01  1.43591431e+02 -4.24596939e+01 ... -4.75371933e+00\n",
            "   -1.04950905e+01 -3.09217811e+00]\n",
            "  ...\n",
            "  [-2.01223450e+02  7.67763519e+01 -6.86572134e-01 ... -1.02624569e+01\n",
            "   -1.09216518e+01 -6.08435345e+00]\n",
            "  [-1.80668106e+02  1.03385742e+02  1.08008442e+01 ... -4.86623192e+00\n",
            "   -7.76387596e+00 -8.29331017e+00]\n",
            "  [-1.74560989e+02  1.24730286e+02  1.72812996e+01 ...  1.18314338e+00\n",
            "   -1.50872707e+00 -6.99646044e+00]]\n",
            "\n",
            " [[-1.18511208e+02  1.76307526e+02  2.73061752e+00 ... -6.50618696e+00\n",
            "   -7.20479536e+00 -1.86905074e+00]\n",
            "  [-6.05259933e+01  1.67550415e+02 -3.18466682e+01 ... -2.69092607e+00\n",
            "   -3.04604578e+00 -3.23872352e+00]\n",
            "  [-4.84111786e+01  1.62739014e+02 -5.61663895e+01 ... -8.08500862e+00\n",
            "   -3.04879284e+00 -3.96722507e+00]\n",
            "  ...\n",
            "  [-1.79641724e+02  1.06360031e+02  1.72258778e+01 ... -1.06443424e+01\n",
            "   -1.17444086e+01 -5.08634186e+00]\n",
            "  [-1.36608826e+02  1.28467667e+02  2.81170425e+01 ... -7.08648157e+00\n",
            "   -6.34916401e+00 -3.08836699e+00]\n",
            "  [-1.12088310e+02  1.37576965e+02  3.54644852e+01 ... -5.06526423e+00\n",
            "   -3.65263373e-01 -2.26490068e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.64490173e+02  1.34086197e+02  2.05033302e+01 ...  6.48252106e+00\n",
            "    1.60911059e+00  2.45665455e+00]\n",
            "  [-1.85031342e+02  1.32336182e+02 -1.19294548e+00 ...  4.31535864e+00\n",
            "    4.67771864e+00  6.86031675e+00]\n",
            "  [-1.80997437e+02  1.26212158e+02 -2.24046516e+01 ...  2.13003826e+00\n",
            "    1.30290613e+01  1.81962051e+01]\n",
            "  ...\n",
            "  [-1.33914658e+02  1.12253876e+02  2.57361259e+01 ... -9.54698277e+00\n",
            "   -1.21324959e+01  2.34009695e+00]\n",
            "  [-1.52861282e+02  1.00796204e+02  3.18286667e+01 ... -8.48359585e+00\n",
            "   -1.75726585e+01 -1.80930614e+00]\n",
            "  [-1.55383438e+02  1.05643333e+02  2.99312325e+01 ... -7.01530695e+00\n",
            "   -1.43117580e+01 -2.89172888e+00]]\n",
            "\n",
            " [[-2.37256165e+02  1.57934357e+02  2.44076729e+01 ... -5.99461555e+00\n",
            "    3.53326619e-01  1.70445786e+01]\n",
            "  [-2.36670410e+02  1.53849365e+02  1.16690245e+01 ... -7.87127686e+00\n",
            "    9.92009830e+00  2.44758930e+01]\n",
            "  [-2.59946381e+02  1.59060547e+02 -3.10186195e+00 ... -3.19832706e+00\n",
            "    2.45623055e+01  3.13216610e+01]\n",
            "  ...\n",
            "  [-2.04071228e+02  1.10965286e+02 -1.89066277e+01 ...  4.84716034e+01\n",
            "    3.27604218e+01  1.19064369e+01]\n",
            "  [-1.85646866e+02  1.35179047e+02 -4.33425140e+00 ...  3.24529724e+01\n",
            "    2.31153259e+01  7.46198416e+00]\n",
            "  [-1.80441071e+02  1.56802170e+02 -5.59716415e+00 ...  1.89322472e+01\n",
            "    1.47127724e+01  4.62527275e+00]]\n",
            "\n",
            " [[-2.28665314e+02  2.25044525e+02 -1.97458191e+01 ...  6.32955360e+00\n",
            "   -9.20101643e-01  2.06848335e+00]\n",
            "  [-1.78330063e+02  2.26989868e+02 -4.58240967e+01 ...  3.23343015e+00\n",
            "   -1.10103951e+01 -1.19224942e+00]\n",
            "  [-1.55969070e+02  2.11147369e+02 -6.03110123e+01 ...  6.38479948e-01\n",
            "   -1.06084042e+01 -1.74479973e+00]\n",
            "  ...\n",
            "  [-2.63022644e+02  1.30457611e+02 -8.30712700e+00 ... -5.50983429e+00\n",
            "   -1.78573570e+01 -1.33887577e+01]\n",
            "  [-1.53038406e+02  1.16649681e+02  1.53291883e+01 ... -5.96724939e+00\n",
            "   -1.35225067e+01 -6.69256306e+00]\n",
            "  [-9.97232895e+01  1.10760750e+02  1.92376862e+01 ... -5.75866175e+00\n",
            "   -8.96203232e+00 -3.75938606e+00]]]\n",
            "X_train [[[ -70.59771729]\n",
            "  [ 104.11129761]\n",
            "  [  -9.18570709]\n",
            "  ...\n",
            "  [  10.68066502]\n",
            "  [  13.60292053]\n",
            "  [  16.48038483]]\n",
            "\n",
            " [[ -75.22388458]\n",
            "  [ 105.33401489]\n",
            "  [  -4.5107007 ]\n",
            "  ...\n",
            "  [   8.25583744]\n",
            "  [  15.17391777]\n",
            "  [  21.2295723 ]]\n",
            "\n",
            " [[-127.81425476]\n",
            "  [  94.88194275]\n",
            "  [  18.87156677]\n",
            "  ...\n",
            "  [  -1.98596549]\n",
            "  [   4.37942505]\n",
            "  [  18.31716347]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-123.01515198]\n",
            "  [ 131.6395874 ]\n",
            "  [ -52.53749847]\n",
            "  ...\n",
            "  [  34.42789459]\n",
            "  [  46.78096008]\n",
            "  [  41.95545959]]\n",
            "\n",
            " [[ -98.65302277]\n",
            "  [ 140.20204163]\n",
            "  [ -35.66329956]\n",
            "  ...\n",
            "  [  17.66217041]\n",
            "  [  31.93544006]\n",
            "  [  35.33816528]]\n",
            "\n",
            " [[-114.65751648]\n",
            "  [ 150.51756287]\n",
            "  [ -15.34147072]\n",
            "  ...\n",
            "  [   7.15116119]\n",
            "  [  19.2341156 ]\n",
            "  [  26.12042618]]]\n",
            "y_train [3 4 5 4 3 4 8 4 8 8 4 3 3 3 8 8 8 8 3 8 8 3 6 4 8 4 4 8 8 3 8 3 8 8 8 8 3\n",
            " 3 6 8 4 8 4 4 3 3 4 6 3 8 4]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 42, 38, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 42, 38, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 19, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 19, 17, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 19, 17, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 9, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 8, 32)          4128      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 9, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 640)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                41024     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 27)                1755      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,523\n",
            "Trainable params: 66,267\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 11s 511ms/step - loss: 5.0810 - accuracy: 0.0196 - val_loss: 10.3680 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 4.6498 - accuracy: 0.0196 - val_loss: 8.7357 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 4.1886 - accuracy: 0.0392 - val_loss: 7.5958 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.8442 - accuracy: 0.0784 - val_loss: 6.7143 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5483 - accuracy: 0.0980 - val_loss: 5.9640 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.2217 - accuracy: 0.1373 - val_loss: 5.3622 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.9449 - accuracy: 0.1961 - val_loss: 4.8522 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 2.7035 - accuracy: 0.3137 - val_loss: 4.4174 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.4810 - accuracy: 0.4118 - val_loss: 4.0587 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.2644 - accuracy: 0.4706 - val_loss: 3.7694 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 2.0904 - accuracy: 0.5098 - val_loss: 3.5232 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.9242 - accuracy: 0.5490 - val_loss: 3.3089 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.7937 - accuracy: 0.6275 - val_loss: 3.1277 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.6447 - accuracy: 0.6471 - val_loss: 2.9777 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.4997 - accuracy: 0.7059 - val_loss: 2.8528 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.3783 - accuracy: 0.7843 - val_loss: 2.7484 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.2601 - accuracy: 0.8039 - val_loss: 2.6601 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.1734 - accuracy: 0.8627 - val_loss: 2.5694 - val_accuracy: 0.1538\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.0741 - accuracy: 0.9020 - val_loss: 2.4910 - val_accuracy: 0.1538\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.9787 - accuracy: 0.9216 - val_loss: 2.4209 - val_accuracy: 0.1538\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.8943 - accuracy: 0.9216 - val_loss: 2.3617 - val_accuracy: 0.1538\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.8211 - accuracy: 0.9216 - val_loss: 2.3111 - val_accuracy: 0.2308\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7565 - accuracy: 0.9412 - val_loss: 2.2710 - val_accuracy: 0.2308\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.7051 - accuracy: 0.9608 - val_loss: 2.2398 - val_accuracy: 0.2308\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6298 - accuracy: 0.9608 - val_loss: 2.2106 - val_accuracy: 0.2308\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.5767 - accuracy: 0.9608 - val_loss: 2.1831 - val_accuracy: 0.2308\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5293 - accuracy: 0.9608 - val_loss: 2.1595 - val_accuracy: 0.3077\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4931 - accuracy: 0.9608 - val_loss: 2.1344 - val_accuracy: 0.3077\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4529 - accuracy: 0.9804 - val_loss: 2.1100 - val_accuracy: 0.3077\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.4258 - accuracy: 1.0000 - val_loss: 2.0877 - val_accuracy: 0.3077\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3965 - accuracy: 0.9804 - val_loss: 2.0672 - val_accuracy: 0.3077\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3673 - accuracy: 1.0000 - val_loss: 2.0515 - val_accuracy: 0.3077\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3582 - accuracy: 1.0000 - val_loss: 2.0355 - val_accuracy: 0.3077\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3234 - accuracy: 1.0000 - val_loss: 2.0151 - val_accuracy: 0.3077\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3035 - accuracy: 1.0000 - val_loss: 1.9930 - val_accuracy: 0.3077\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step - loss: 1.6737 - accuracy: 0.5882\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # generate train, validation and test sets\n",
        "    X_train, y_train, X_validation, y_validation, X_test, y_test = prepare_dataset(DATA_PATH)\n",
        "    print('X_train',X_train[0])\n",
        "    print('y_train',y_train)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape=input_shape, learning_rate=LEARNING_RATE)\n",
        "\n",
        "    # train network\n",
        "    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)\n",
        "\n",
        "    # plot accuracy/loss for training/validation set as a function of the epochs\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate network on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    # print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))\n",
        "\n",
        "    # save model\n",
        "    m = model.save(SAVED_MODEL_PATH)\n",
        "    print(m)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SAVED_MODEL_PATH = \"model.h5\"\n",
        "SAMPLES_TO_CONSIDER = 22050\n",
        "\n",
        "class _Keyword_Spotting_Service:\n",
        "    \"\"\"Singleton class for keyword spotting inference with trained models.\n",
        "\n",
        "    :param model: Trained model\n",
        "    \"\"\"\n",
        "\n",
        "    model = None\n",
        "    _mapping = {\n",
        "    1:\"Bis'mi\",\n",
        "    2:\"Al-lahi\",\n",
        "    3:\"Al-rahmaani\",\n",
        "    4:\"Al-raheemi\",\n",
        "    5:\"Alhamdu\",\n",
        "    6:\"lillaahi\",\n",
        "    7:\"Rabbil\",\n",
        "    8:\"aalameen\",\n",
        "    9:\"Ar-Rahmaan\",\n",
        "    10:\"Ar-Raheem\",\n",
        "    11:\"Maaliki\",\n",
        "    12:\"Yumid\",\n",
        "    13:\"Diin\",\n",
        "    14:\"Iyyaka\",\n",
        "    15:\"Na'abudu\",\n",
        "    16:\"Iyyaka\",\n",
        "    17:\"Nasta'een\",\n",
        "    18:\"Ihdinas\",\n",
        "    19:\"Siraatal\",\n",
        "    20:\"Mustaqeem\",\n",
        "    21:\"Siraatal\",\n",
        "    22:\"Ladheena\",\n",
        "    23:\"An'amta\",\n",
        "    24:\"Alaihim\",\n",
        "    25:\"Ghayril\",\n",
        "    26:\"Maghdubi\",\n",
        "    27:\"Alaihim\",\n",
        "    28:\"Wala al-dalina\"\n",
        "}\n",
        "\n",
        "    _instance = None\n",
        "\n",
        "\n",
        "    def predict(self, file_path):\n",
        "        \"\"\"\n",
        "\n",
        "        :param file_path (str): Path to audio file to predict\n",
        "        :return predicted_keyword (str): Keyword predicted by the model\n",
        "        \"\"\"\n",
        "\n",
        "        # extract MFCC\n",
        "        MFCCs = self.preprocess(file_path)\n",
        "\n",
        "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
        "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        # get the predicted label\n",
        "        predictions = self.model.predict(MFCCs) # a 2d array [[]]\n",
        "        predicted_index = np.argmax(predictions)\n",
        "        print('predicted index',predicted_index)\n",
        "        # index return the index which has highest score\n",
        "        predicted_keyword = self._mapping[predicted_index]\n",
        "        # print('prediction',predicted_index,predicted_keyword)\n",
        "        return predicted_keyword\n",
        "\n",
        "\n",
        "    def preprocess(self, file_path, num_mfcc=40, n_fft=2048, hop_length=512):\n",
        "        \"\"\"Extract MFCCs from audio file.\n",
        "\n",
        "        :param file_path (str): Path of audio file\n",
        "        :param num_mfcc (int): # of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply STFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for STFT. Measured in # of samples\n",
        "\n",
        "        :return MFCCs (ndarray): 2-dim array with MFCC data of shape (# time steps, # coefficients)\n",
        "        \"\"\"\n",
        "\n",
        "        # load audio file\n",
        "        signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "            # ensure consistency of the length of the signal (if the len of the array greater than trained array, we'll limit to it as per the trained array length)\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "            return MFCCs.T\n",
        "        else:\n",
        "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "            # extract MFCCs\n",
        "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                         hop_length=hop_length)\n",
        "            return MFCCs.T\n",
        "\n",
        "\n",
        "def Keyword_Spotting_Service():\n",
        "    \"\"\"Factory function for Keyword_Spotting_Service class.\n",
        "\n",
        "    :return _Keyword_Spotting_Service._instance (_Keyword_Spotting_Service):\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure an instance is created only the first time the factory function is called\n",
        "    if _Keyword_Spotting_Service._instance is None:\n",
        "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
        "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "    return _Keyword_Spotting_Service._instance\n"
      ],
      "metadata": {
        "id": "jumpKqOwTvg9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # create 2 instances of the keyword spotting service\n",
        "    kss = Keyword_Spotting_Service()\n",
        "    kss1 = Keyword_Spotting_Service()\n",
        "\n",
        "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
        "    assert kss is kss1\n",
        "\n",
        "    # make a prediction\n",
        "    keyword = kss.predict(\"012.wav\")\n",
        "    print(keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPTnzIvCWkOW",
        "outputId": "0ad8a05f-58ee-44ea-e5bd-067baa799515"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 223ms/step\n",
            "predicted index 8\n",
            "aalameen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UimezjXdWn0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1yugasZphHK9upW8HKd7QUf5nrK9JOqKe",
      "authorship_tag": "ABX9TyOo4bLav7e6bPQfXoylVVD8",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}